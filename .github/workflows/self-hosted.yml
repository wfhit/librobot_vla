name: Self-Hosted CI

# GPU tests on self-hosted runner using project's Docker image from ghcr.io
# The train image is pulled automatically with GITHUB_TOKEN authentication
#
# Prerequisites:
#   1. Self-hosted runner with labels: self-hosted, linux, x64
#   2. NVIDIA Container Toolkit installed
#   3. Docker configured with nvidia runtime

on:
  workflow_run:
    workflows: ["Docker Build"]
    types: [completed]
    branches: [main]
  workflow_dispatch:
    inputs:
      image_tag:
        description: 'Docker image tag (default: latest)'
        required: false
        default: 'latest'
        type: string

jobs:
  gpu-tests:
    name: GPU Tests
    if: github.event_name == 'workflow_dispatch' || github.event.workflow_run.conclusion == 'success'
    runs-on: [self-hosted, linux, x64]
    container:
      image: ghcr.io/${{ github.repository_owner }}/librobot-train:${{ inputs.image_tag || 'latest' }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
      options: --user root --gpus all
    timeout-minutes: 30
    permissions:
      contents: read
      packages: read

    steps:
      - uses: actions/checkout@v4

      - name: Verify GPU environment
        run: |
          echo "Image: ghcr.io/${{ github.repository_owner }}/librobot-train:${{ inputs.image_tag || 'latest' }}"
          python3 --version
          python3 -c "import torch; print(f'PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}, Devices: {torch.cuda.device_count()}')"
          nvidia-smi --query-gpu=name,memory.total --format=csv,noheader || true

      - name: Install project
        run: pip3 install --break-system-packages -e ".[dev]"

      - name: Run GPU tests
        run: |
          # Exit code 5 means no tests collected - OK if no GPU tests exist yet
          pytest tests/ -v --tb=short -m "gpu" --timeout=600 || [ $? -eq 5 ]

      - name: Run full test suite
        run: pytest tests/ -v --tb=short -m "not slow" --timeout=300
