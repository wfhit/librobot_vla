# Wheel Loader VLA Training Configuration
# This example demonstrates training a VLA model for autonomous wheel loader operation

# Experiment metadata
experiment:
  name: "wheel_loader_groot"
  description: "Train GR00T-style VLA for wheel loader autonomous operation"
  tags: ["wheel_loader", "groot", "diffusion", "heavy_equipment"]

# Model configuration
model:
  framework: "groot_style"  # Use GR00T architecture
  vlm:
    name: "qwen_vl"
    pretrained: true
    freeze: true  # Freeze VLM for stable training
  
  action_head:
    type: "diffusion"
    num_steps: 100
    beta_schedule: "linear"
    hidden_dim: 512
  
  state_encoder:
    type: "mlp"
    hidden_dim: 256
    num_layers: 3

# Robot configuration
robot:
  type: "wheel_loader"
  action_dim: 6  # steering, throttle, brake, bucket_tilt, boom_lift, transmission
  state_dim: 12  # position, velocity, hydraulic pressure, etc.
  
  cameras:
    - name: "front_camera"
      resolution: [224, 224]
    - name: "rear_camera"
      resolution: [224, 224]
    - name: "bucket_camera"
      resolution: [224, 224]
  
  safety:
    max_speed: 5.0  # m/s
    geofence_enabled: true
    emergency_stop_enabled: true

# Dataset configuration
dataset:
  name: "wheel_loader_demos"
  path: "/workspace/data/wheel_loader"
  train_split: 0.9
  val_split: 0.1
  
  transforms:
    image:
      - type: "resize"
        size: [224, 224]
      - type: "normalize"
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]
    
    action:
      - type: "normalize"
        method: "minmax"
      - type: "clip"
        min: -1.0
        max: 1.0

# Training configuration
training:
  # Optimization
  optimizer:
    type: "adamw"
    lr: 0.0001
    weight_decay: 0.01
    betas: [0.9, 0.999]
  
  # Learning rate schedule
  scheduler:
    type: "cosine"
    warmup_steps: 1000
    min_lr: 0.00001
  
  # Training loop
  batch_size: 32
  num_epochs: 100
  gradient_accumulation_steps: 1
  max_grad_norm: 1.0
  
  # Mixed precision
  mixed_precision: true
  precision: "bf16"
  
  # Distributed training
  distributed:
    backend: "nccl"
    find_unused_parameters: false
  
  # Validation
  val_every_n_steps: 500
  save_every_n_steps: 1000
  
  # Checkpointing
  save_top_k: 3
  monitor_metric: "val/action_mse"
  monitor_mode: "min"

# Logging configuration
logging:
  use_wandb: true
  wandb_project: "librobot-wheel-loader"
  wandb_entity: null
  
  use_tensorboard: true
  tensorboard_dir: "outputs/tensorboard"
  
  log_every_n_steps: 10
  log_images_every_n_steps: 100

# Output paths
output:
  base_dir: "outputs/wheel_loader_groot"
  checkpoint_dir: "checkpoints"
  log_dir: "logs"
  visualizations_dir: "visualizations"

# Reproducibility
seed: 42
deterministic: false  # Set to true for full reproducibility (slower)
