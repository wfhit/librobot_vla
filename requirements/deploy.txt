# Minimal deployment dependencies for LibroBot VLA inference
# Use this for production deployment where training is not needed

# Core ML framework (CPU-only or GPU runtime)
torch>=2.5.0
torchvision>=0.20.0

# Transformers and model support
transformers>=4.40.0
accelerate>=0.27.0
tokenizers>=0.19.0

# Inference server
fastapi>=0.109.0
uvicorn[standard]>=0.27.0
pydantic>=2.5.0

# Image processing
pillow>=10.0.0
opencv-python-headless>=4.9.0

# Utilities
numpy>=1.24.0
pyyaml>=6.0.0
tqdm>=4.66.0

# Optional: Quantization support
# bitsandbytes>=0.41.0  # Uncomment for 4-bit/8-bit quantization
# optimum>=1.16.0  # Uncomment for ONNX Runtime
